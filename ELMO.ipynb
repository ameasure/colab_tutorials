{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ameasure/try_git/blob/master/ELMO.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "GgkSG9nKKpBN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n"
      ]
    },
    {
      "metadata": {
        "id": "YIxCSR6DH_Og",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0d9da7ff-1701-4e48-b31d-504a435abce6"
      },
      "cell_type": "code",
      "source": [
        "!wget 'https://github.com/ameasure/autocoding-class/raw/master/msha.xlsx'\n",
        "!pip install xlrd\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log.1’.\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.6/dist-packages (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pxaNtghjKs9B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download Training and Validation Data"
      ]
    },
    {
      "metadata": {
        "id": "lpE9aQu0IWrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "580bb292-e80f-40a1-8831-631eb3c4ee4c"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('msha.xlsx')\n",
        "df['ACCIDENT_YEAR'] = df['ACCIDENT_DT'].apply(lambda x: x.year)\n",
        "df['ACCIDENT_YEAR'].value_counts()\n",
        "df_train = df[df['ACCIDENT_YEAR'].isin([2010, 2011])].copy()\n",
        "df_valid = df[df['ACCIDENT_YEAR'] == 2012].copy()\n",
        "print('training rows:', len(df_train))\n",
        "print('validation rows:', len(df_valid))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training rows: 18681\n",
            "validation rows: 9032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hl8JRrWrIswH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "label_encoder = LabelBinarizer().fit(df_train['INJ_BODY_PART'])\n",
        "y_train = label_encoder.transform(df_train['INJ_BODY_PART'])\n",
        "y_valid = label_encoder.transform(df_valid['INJ_BODY_PART'])\n",
        "n_classes = len(label_encoder.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WBGaCvvGHDYZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ELMO embeddings\n",
        "\n",
        "ELMO is a pretrained RNN language model. A copy of  it is documented and available on [tensorflow_hub](https://tfhub.dev/google/elmo/2). We can use the tensorflow_hub module to load a copy of the model as follows:"
      ]
    },
    {
      "metadata": {
        "id": "mUfNPnF3Izt5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c5fb5646-3c6a-4159-fff8-5bebe0c56a57"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Lambda, GlobalMaxPooling1D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Read in the pre-trained elmo model\n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "\n",
        "# Create a function that accepts a raw string input x, passes it into the elmo \n",
        "# model, and returns a sequence of vectors representing the input. Putting this\n",
        "# in a function allows us to connect the elmo_model to a Keras model using a\n",
        "# Lambda layer.\n",
        "def get_elmo_embedding(x):\n",
        "    return elmo_model(tf.squeeze(tf.cast(x, tf.string)), \n",
        "                      signature='default',\n",
        "                      as_dict=True)['elmo']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "WyuZ0TsuJoKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define and Link the models\n",
        "\n",
        "We can now load and link this pretrained model with a new model of our design as follows:"
      ]
    },
    {
      "metadata": {
        "id": "gBCbwwpVJUDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ccd39ff-e29c-4076-ef32-71dc481d202b"
      },
      "cell_type": "code",
      "source": [
        "# specify the input - ELMO accepts a 1 dimensional vector where each entry is \n",
        "# a string representing an injury narrative\n",
        "text_input = Input(shape=(1,), dtype='string')\n",
        "# A Lambda layer performs the computation defined by the function it receives\n",
        "# In this case the function feeds data into the ELMO model and returns the output\n",
        "# output_shape - tells Keras the output of this layer is a variable length \n",
        "# sequence of 1024 dimensional vectors, each representing a word in the input narrative.\n",
        "elmo_embedding = Lambda(get_elmo_embedding, \n",
        "                        output_shape=(None, 1024))(text_input)\n",
        "max_pooling = GlobalMaxPooling1D()(elmo_embedding)\n",
        "# feed the output of the ELMO model into the output layer\n",
        "# the output layer will predict part_of_body probabilities\n",
        "output = Dense(units=n_classes, activation='softmax', name='output')(max_pooling)\n",
        "\n",
        "# tell Keras which layers are the inputs and outputs of our model\n",
        "model = Model(inputs=text_input, outputs=[output])\n",
        "# optimizer - the algorithm for calculating the optimal weights (ADAM is a\n",
        "#   variant of gradient descent)\n",
        "# loss - the loss function we will attempt to minimize through gradient descent (cross_entropy)\n",
        "# metrics - the validation metrics we will calculate after each epoch (accuracy)\n",
        "adam = Adam(lr=.004)\n",
        "model.compile(optimizer=adam, \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nPwH4AkDOrv4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ]
    },
    {
      "metadata": {
        "id": "AHWCsvIOHCKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "7dd0fe65-fe77-4b69-f970-bcc805e0e196"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x=df_train['NARRATIVE'].as_matrix(), y=y_train,\n",
        "          validation_data=(df_valid['NARRATIVE'].as_matrix(), y_valid),\n",
        "          batch_size=64, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18681 samples, validate on 9032 samples\n",
            "Epoch 1/20\n",
            "18681/18681 [==============================] - 502s 27ms/step - loss: 2.9360 - acc: 0.3406 - val_loss: 2.2060 - val_acc: 0.4739\n",
            "Epoch 2/20\n",
            "18681/18681 [==============================] - 492s 26ms/step - loss: 2.2390 - acc: 0.4958 - val_loss: 2.1938 - val_acc: 0.5187\n",
            "Epoch 3/20\n",
            " 7104/18681 [==========>...................] - ETA: 3:25 - loss: 2.1333 - acc: 0.5298"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}