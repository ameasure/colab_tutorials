{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ameasure/try_git/blob/master/ELMO.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "GgkSG9nKKpBN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n"
      ]
    },
    {
      "metadata": {
        "id": "YIxCSR6DH_Og",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "56052f24-2012-418e-edab-67e26baf3db4"
      },
      "cell_type": "code",
      "source": [
        "!wget 'https://github.com/ameasure/autocoding-class/raw/master/msha.xlsx'\n",
        "!pip install xlrd\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log’.\n",
            "Collecting xlrd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/e6/e95c4eec6221bfd8528bcc4ea252a850bffcc4be88ebc367e23a1a84b0bb/xlrd-1.1.0-py2.py3-none-any.whl (108kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 5.7MB/s \n",
            "\u001b[?25hInstalling collected packages: xlrd\n",
            "Successfully installed xlrd-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pxaNtghjKs9B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download Training and Validation Data"
      ]
    },
    {
      "metadata": {
        "id": "lpE9aQu0IWrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bec01974-bf48-4ced-d98f-866a19770a7f"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('msha.xlsx')\n",
        "df['ACCIDENT_YEAR'] = df['ACCIDENT_DT'].apply(lambda x: x.year)\n",
        "df['ACCIDENT_YEAR'].value_counts()\n",
        "df_train = df[df['ACCIDENT_YEAR'].isin([2010, 2011])].copy()\n",
        "df_valid = df[df['ACCIDENT_YEAR'] == 2012].copy()\n",
        "print('training rows:', len(df_train))\n",
        "print('validation rows:', len(df_valid))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training rows: 18681\n",
            "validation rows: 9032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hl8JRrWrIswH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "label_encoder = LabelBinarizer().fit(df_train['INJ_BODY_PART'])\n",
        "y_train = label_encoder.transform(df_train['INJ_BODY_PART'])\n",
        "y_valid = label_encoder.transform(df_valid['INJ_BODY_PART'])\n",
        "n_classes = len(label_encoder.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WBGaCvvGHDYZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ELMO embeddings\n",
        "\n",
        "ELMO is a pretrained RNN language model. We can download a trained copy of the model using tensorflow_hub as follows:"
      ]
    },
    {
      "metadata": {
        "id": "mUfNPnF3Izt5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "d384674c-e3d0-406b-9473-f8ad6d6498cb"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Lambda, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# start a Tensorflow session to manage GPU resources and computations\n",
        "sess = tf.Session()\n",
        "# connect Keras to the Tensorflow sesssion\n",
        "K.set_session(sess)\n",
        "# read in the pre-trained elmo model\n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "# add the elmo-defined variables to our Tensorflow session\n",
        "sess.run(tf.global_variables_initializer())\n",
        "# add the elmo-defined tables to our Tensorflow session\n",
        "sess.run(tf.tables_initializer())\n",
        "\n",
        "# create a function that feeds a raw string input into the elmo model\n",
        "# and returns a Keras-compatible vector output\n",
        "def get_elmo_embedding(x):\n",
        "    return elmo_model(tf.squeeze(tf.cast(x, tf.string)), \n",
        "                      signature='default',\n",
        "                      as_dict=True)['elmo']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n",
            "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WyuZ0TsuJoKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define and Link the models\n",
        "\n",
        "We can now load and link this pretrained model with a new model of our design as follows:"
      ]
    },
    {
      "metadata": {
        "id": "gBCbwwpVJUDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9621c46d-2fb4-4b29-b9a4-d363544b3aca"
      },
      "cell_type": "code",
      "source": [
        "# specify the input - ELMO accepts a 1 dimensional vector where\n",
        "# each entry is an injury narrative\n",
        "text_input = Input(shape=(1,), dtype='string')\n",
        "# feed the string input into the ELMO model\n",
        "elmo_embedding = Lambda(get_elmo_embedding, \n",
        "                        output_shape=(None, 1024))(text_input)\n",
        "average_pooling = GlobalAveragePooling1D()(elmo_embedding)\n",
        "# feed the output of the ELMO model into the output layer\n",
        "# the output layer will predict part_of_body probabilities\n",
        "output = Dense(units=n_classes, activation='softmax', name='output')(average_pooling)\n",
        "\n",
        "# tell Keras which layers are the inputs and outputs of our model\n",
        "model = Model(inputs=text_input, outputs=[output])\n",
        "# optimizer - the algorithm for calculating the optimal weights (ADAM is a\n",
        "#   variant of gradient descent)\n",
        "# loss - the loss function we will attempt to minimize through gradient descent (cross_entropy)\n",
        "# metrics - the validation metrics we will calculate after each epoch (accuracy)\n",
        "adam = Adam(lr=.004)\n",
        "model.compile(optimizer=adam, \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nPwH4AkDOrv4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ]
    },
    {
      "metadata": {
        "id": "AHWCsvIOHCKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "143ec8e9-dd4d-4b17-88c7-76f356e7f18e"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x=df_train['NARRATIVE'].as_matrix(), y=y_train,\n",
        "          validation_data=(df_valid['NARRATIVE'].as_matrix(), y_valid),\n",
        "          batch_size=64, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18681 samples, validate on 9032 samples\n",
            "Epoch 1/20\n",
            " 1664/18681 [=>............................] - ETA: 6:08 - loss: 3.1617 - acc: 0.1911"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}