{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameasure/colab_tutorials/blob/master/Finetune2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic5-oTjJodK_",
        "colab_type": "text"
      },
      "source": [
        "Transfer Learning with Finetune \n",
        "\n",
        "https://https://github.com/IndicoDataSolutions/finetune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMc7WPBRob2v",
        "colab_type": "code",
        "outputId": "20107046-1b08-4f3a-ce7d-c9ff644e2f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "!pip install -U finetune\n",
        "#!python -m spacy download en_core_web_sm\n",
        "#!python -m spacy link en_core_web_sm en\n",
        "!pip install tables\n",
        "!pip install xlrd\n",
        "!wget 'https://github.com/ameasure/autocoding-class/raw/master/msha.xlsx'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: finetune in /usr/local/lib/python3.6/dist-packages (0.6.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from finetune) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: lxml>=4.3.3 in /usr/local/lib/python3.6/dist-packages (from finetune) (4.3.4)\n",
            "Requirement already satisfied, skipping upgrade: spacy>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from finetune) (2.1.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from finetune) (0.21.2)\n",
            "Requirement already satisfied, skipping upgrade: imblearn>=0.0 in /usr/local/lib/python3.6/dist-packages (from finetune) (0.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from finetune) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.12.0 in /usr/local/lib/python3.6/dist-packages (from finetune) (0.13.2)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.2.4 in /usr/local/lib/python3.6/dist-packages (from finetune) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from finetune) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: ftfy>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from finetune) (5.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.23.1 in /usr/local/lib/python3.6/dist-packages (from finetune) (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: regex>=2019.03.12 in /usr/local/lib/python3.6/dist-packages (from finetune) (2019.6.8)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from finetune) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: bs4>=0.0.1 in /usr/local/lib/python3.6/dist-packages (from finetune) (0.0.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (0.0.6)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (0.2.4)\n",
            "Requirement already satisfied, skipping upgrade: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (7.0.4)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->finetune) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (from imblearn>=0.0->finetune) (0.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2.4->finetune) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy>=4.4.0->finetune) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.1->finetune) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.1->finetune) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4>=0.0.1->finetune) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0->finetune) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0->finetune) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0->finetune) (2019.3.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0->finetune) (3.0.4)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (3.4.4)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.6.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tables) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from tables) (1.16.4)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "--2019-06-16 04:21:06--  https://github.com/ameasure/autocoding-class/raw/master/msha.xlsx\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ameasure/autocoding-class/master/msha.xlsx [following]\n",
            "--2019-06-16 04:21:06--  https://raw.githubusercontent.com/ameasure/autocoding-class/master/msha.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4183086 (4.0M) [application/octet-stream]\n",
            "Saving to: ‘msha.xlsx.3’\n",
            "\n",
            "msha.xlsx.3         100%[===================>]   3.99M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-06-16 04:21:06 (48.7 MB/s) - ‘msha.xlsx.3’ saved [4183086/4183086]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdpWCKhdxUNB",
        "colab_type": "code",
        "outputId": "f953b2f6-35f2-49c1-8948-b0dea4928a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('msha.xlsx')\n",
        "df['ACCIDENT_YEAR'] = df['ACCIDENT_DT'].apply(lambda x: x.year)\n",
        "df['ACCIDENT_YEAR'].value_counts()\n",
        "df_train = df[df['ACCIDENT_YEAR'].isin([2010, 2011])][0:192].copy()\n",
        "df_valid = df[df['ACCIDENT_YEAR'] == 2012][0:96].copy()\n",
        "print('training rows:', len(df_train))\n",
        "print('validation rows:', len(df_valid))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training rows: 192\n",
            "validation rows: 96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLHB5xmDcOi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import summary\n",
        "%load_ext tensorboard.notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki8pkZxTcQ3p",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:6015/": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNTAwIChJbnRlcm5hbCBTZXJ2ZXIgRXJyb3IpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj41MDAuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1461"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 500,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cee7616b-5bf3-4231-fc77-8ab90324df7e"
      },
      "source": [
        "%tensorboard --logdir 'my_fine_tune'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6015 (pid 1922), started 0:03:37 ago. (Use '!kill 1922' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6015\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 600));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQMlXCHuhpIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3492a76-9414-4267-c05d-467fbe9c1495"
      },
      "source": [
        "!kill 1922"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: kill: (1922) - No such process\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxOweCiZA0KU",
        "colab_type": "code",
        "outputId": "4e9b3cc2-7b4c-450e-d5c3-a333a3fe4af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "from finetune import Classifier\n",
        "\n",
        "# max_length is the maximum number of words we will use from each narrative\n",
        "# behind the scenes finetune is setting aside 5% of the training data for validation\n",
        "model = Classifier(batch_size=32, max_length=90, n_epochs=4, val_size=32,\n",
        "                   tensorboard_folder='my_fine_tune')\n",
        "model.fit(df_train['NARRATIVE'], df_train['INJ_BODY_PART'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0616 04:21:28.013924 140606581958528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/finetune/saver.py:66: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "W0616 04:21:28.024330 140606581958528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/finetune/__init__.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0616 04:21:28.025609 140606581958528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/finetune/__init__.py:23: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
            "\n",
            "I0616 04:21:28.067167 140606581958528 config.py:78]  Visible GPUs: {0: Tesla T4}\n",
            "Epoch 2/4:  40%|████      | 64/160 [00:01<00:01, 52.11it/s]\n",
            "Validation:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3/4:  20%|██        | 32/160 [00:00<00:02, 56.43it/s]\n",
            "Validation:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4/4:   0%|          | 0/160 [00:00<?, ?it/s]\n",
            "Validation:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4/4:  80%|████████  | 128/160 [00:04<00:01, 17.85it/s]\n",
            "Validation:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4/4: 100%|██████████| 160/160 [00:07<00:00, 15.08it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWbjdsG29Pqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate preditions\n",
        "df_valid['PREDICTED_PART'] = model.predict(df_valid['NARRATIVE'].values)\n",
        "# look at a sample\n",
        "df_valid[['NARRATIVE', 'INJ_BODY_PART', 'PREDICTED_PART']].sample(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmb9BX0RA9bN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.max_colwidth=500\n",
        "\n",
        "df_valid['PROB_DICT'] = model.predict_proba(df_valid['NARRATIVE'].values)\n",
        "df_valid[['NARRATIVE', 'PREDICTED_PART', 'PROB_DICT']].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvZ3fBw3BBWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function that takes a row of our dataframe and returns the predicted probability\n",
        "def get_probability(row):\n",
        "    predicted_part = row['PREDICTED_PART']\n",
        "    probability_dict = row['PROB_DICT']\n",
        "    return probability_dict[predicted_part]\n",
        "\n",
        "# apply get_probability to each row in our dataframe and store the result\n",
        "df_valid['PREDICTED_PROB'] = df_valid.apply(func=get_probability, axis=1)\n",
        "# take a peak at what we get\n",
        "df_valid[['NARRATIVE', 'INJ_BODY_PART', 'PREDICTED_PART', 'PREDICTED_PROB']].sample(5).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6Tzjh2JBD4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "mf1 = f1_score(df_valid['INJ_BODY_PART'], df_valid['PREDICTED_PART'], average='macro')\n",
        "acc = accuracy_score(df_valid['INJ_BODY_PART'], df_valid['PREDICTED_PART'])\n",
        "print('macro-f1:', mf1)\n",
        "print('accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htL4vk4BM0Jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}