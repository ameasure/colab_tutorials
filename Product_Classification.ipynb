{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Product Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameasure/colab_tutorials/blob/master/Product_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agP0BNV04XdT",
        "colab_type": "text"
      },
      "source": [
        "# Install Libraries\n",
        "* tensorflow 2\n",
        "* transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxF-VtgOeU40",
        "colab_type": "code",
        "outputId": "a27131ae-7853-4120-a7c8-37fb80b66cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# upgrade to tensorflow 2\n",
        "pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.2.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rt7vsj6dxIc",
        "colab_type": "code",
        "outputId": "5cbb902a-595e-49a9-e235-78a3a6f3f613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# install huggingface transformers library\n",
        "pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.16.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.9.243)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.8.19)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.243 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.12.243)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->transformers) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yofIq5UEvPUW",
        "colab_type": "text"
      },
      "source": [
        "# Read in Data\n",
        "Separate into training and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbJQYIj_dTwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(r'/content/Stats Poland ECOICOP data translated to English and French.xlsx')\n",
        "df_train = df.sample(frac=.8)\n",
        "df_valid = df[~df.index.isin(df_train.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdG3zBe_kX0j",
        "colab_type": "code",
        "outputId": "ec137de1-ef6c-44b1-9299-879ba77eaa28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(df_train))\n",
        "print(len(df_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13679\n",
            "3420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyGHxxYx3vPf",
        "colab_type": "text"
      },
      "source": [
        "# Load pretrained Tokenizer and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re1LCgAudvEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets\n",
        "from transformers import *\n",
        "\n",
        "# Load dataset, tokenizer, model from pretrained model/vocabulary\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "pt_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpRBp08_30oU",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize and Pad Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBF4CvqThiLZ",
        "colab_type": "code",
        "outputId": "94ee26a0-0263-4abe-e915-1899ff52b900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def pad_sequences(texts, max_seq_len):\n",
        "  token_lengths = []\n",
        "  X = []\n",
        "  for text in texts:\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "    token_lengths.append(len(tokens))\n",
        "    # pad to max_seq_len\n",
        "    while len(tokens) < max_seq_len:\n",
        "      tokens.append(tokenizer.pad_token_id)\n",
        "    # chop down to max_seq_len\n",
        "    tokens = tokens[: max_seq_len]\n",
        "    assert len(tokens) >= max_seq_len, f'{len(tokens)} !>= {max_seq_len}, {tokens}'\n",
        "    # if the last token is not padding or a separator we truncated and need to add a separator\n",
        "    if tokens[-1] not in [tokenizer.pad_token_id, tokenizer.sep_token_id]:\n",
        "      tokens = tokens[0: max_seq_len-1]\n",
        "      tokens.append(tokenizer.sep_token_id)\n",
        "    assert len(tokens) == max_seq_len, f'{len(tokens)} != {max_seq_len}, {tokens}'\n",
        "    X.append(np.array(tokens))\n",
        "  print(f'max token length: {np.max(token_lengths)}')\n",
        "  return np.stack(X)\n",
        "\n",
        "X_train = pad_sequences(df_train['Desc_E'], max_seq_len=40)\n",
        "X_valid = pad_sequences(df_valid['Desc_E'], max_seq_len=40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max token length: 36\n",
            "max token length: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCUVWZMr36rz",
        "colab_type": "text"
      },
      "source": [
        "# Convert Codes to Indexes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqlb14z_Q-Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert codes to indexes\n",
        "le = LabelEncoder()\n",
        "le.fit(df['Code_E'])\n",
        "y_train = le.transform(df_train['Code_E'])\n",
        "y_valid = le.transform(df_valid['Code_E'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71DmC3dW39qT",
        "colab_type": "text"
      },
      "source": [
        "# Specify Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtNFkJZfUra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "\n",
        "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule \n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "# Create custom model from pretrained model and other pieces\n",
        "class MyNet(tf.keras.Model):\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    super(MyNet, self).__init__(**kwargs)\n",
        "    self.model = pt_model.layers[0]\n",
        "    self.mean = tf.keras.layers.GlobalAveragePooling1D()\n",
        "    self.do = tf.keras.layers.Dropout(rate=.5)\n",
        "    self.dense = tf.keras.layers.Dense(output_dim, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.model(x)\n",
        "    x = self.mean(x[0])\n",
        "    x = self.do(x)\n",
        "    x = self.dense(x)\n",
        "    return x\n",
        "\n",
        "model = MyNet(output_dim=len(le.classes_))\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r5fSGU24US8",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTpgPiHYv-nz",
        "colab_type": "code",
        "outputId": "86eeb875-8a72-4cad-8cf6-8a035881e902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Train and evaluate using tf.keras.Model.fit()\n",
        "history = model.fit(x=X_train, y=y_train, epochs=10, batch_size=256,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13679 samples, validate on 3420 samples\n",
            "Epoch 1/10\n",
            "13679/13679 [==============================] - 108s 8ms/sample - loss: 2.2192 - accuracy: 0.4617 - val_loss: 1.1682 - val_accuracy: 0.7146\n",
            "Epoch 2/10\n",
            "13679/13679 [==============================] - 106s 8ms/sample - loss: 1.0093 - accuracy: 0.7527 - val_loss: 0.7382 - val_accuracy: 0.8070\n",
            "Epoch 3/10\n",
            "13679/13679 [==============================] - 106s 8ms/sample - loss: 0.6280 - accuracy: 0.8412 - val_loss: 0.5589 - val_accuracy: 0.8459\n",
            "Epoch 4/10\n",
            "13679/13679 [==============================] - 106s 8ms/sample - loss: 0.4403 - accuracy: 0.8849 - val_loss: 0.5124 - val_accuracy: 0.8635\n",
            "Epoch 5/10\n",
            "13679/13679 [==============================] - 105s 8ms/sample - loss: 0.3395 - accuracy: 0.9095 - val_loss: 0.4610 - val_accuracy: 0.8822\n",
            "Epoch 6/10\n",
            "13679/13679 [==============================] - 106s 8ms/sample - loss: 0.2609 - accuracy: 0.9309 - val_loss: 0.4354 - val_accuracy: 0.8947\n",
            "Epoch 7/10\n",
            "13679/13679 [==============================] - 105s 8ms/sample - loss: 0.2083 - accuracy: 0.9438 - val_loss: 0.4450 - val_accuracy: 0.8924\n",
            "Epoch 8/10\n",
            "13679/13679 [==============================] - 105s 8ms/sample - loss: 0.1634 - accuracy: 0.9577 - val_loss: 0.4159 - val_accuracy: 0.9009\n",
            "Epoch 9/10\n",
            "13679/13679 [==============================] - 105s 8ms/sample - loss: 0.1335 - accuracy: 0.9624 - val_loss: 0.4484 - val_accuracy: 0.8953\n",
            "Epoch 10/10\n",
            "13679/13679 [==============================] - 106s 8ms/sample - loss: 0.1047 - accuracy: 0.9721 - val_loss: 0.4425 - val_accuracy: 0.9020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SNlx-5l9WC9",
        "colab_type": "code",
        "outputId": "4997148c-7223-419b-8c4c-dbbe0d8a80cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Train and evaluate using tf.keras.Model.fit()\n",
        "history = model.fit(x=X_train, y=y_train, epochs=10, batch_size=128,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13679 samples, validate on 3420 samples\n",
            "Epoch 1/5\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.1145 - accuracy: 0.9667 - val_loss: 0.4482 - val_accuracy: 0.8985\n",
            "Epoch 2/5\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0941 - accuracy: 0.9740 - val_loss: 0.4607 - val_accuracy: 0.8997\n",
            "Epoch 3/5\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0732 - accuracy: 0.9785 - val_loss: 0.4614 - val_accuracy: 0.9000\n",
            "Epoch 4/5\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0577 - accuracy: 0.9840 - val_loss: 0.4840 - val_accuracy: 0.8997\n",
            "Epoch 5/5\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.4795 - val_accuracy: 0.9032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1vhf6k19X6B",
        "colab_type": "code",
        "outputId": "3a1060b6-1e2c-4eb3-c8f5-904c03fb8041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Train and evaluate using tf.keras.Model.fit()\n",
        "history = model.fit(x=X_train, y=y_train, epochs=10, batch_size=128,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13679 samples, validate on 3420 samples\n",
            "Epoch 1/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0344 - accuracy: 0.9914 - val_loss: 0.4919 - val_accuracy: 0.9056\n",
            "Epoch 2/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0335 - accuracy: 0.9907 - val_loss: 0.5042 - val_accuracy: 0.9041\n",
            "Epoch 3/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0309 - accuracy: 0.9919 - val_loss: 0.5105 - val_accuracy: 0.9047\n",
            "Epoch 4/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0256 - accuracy: 0.9936 - val_loss: 0.5016 - val_accuracy: 0.9050\n",
            "Epoch 5/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0278 - accuracy: 0.9925 - val_loss: 0.5153 - val_accuracy: 0.9102\n",
            "Epoch 6/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0211 - accuracy: 0.9947 - val_loss: 0.5296 - val_accuracy: 0.9073\n",
            "Epoch 7/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.5382 - val_accuracy: 0.9038\n",
            "Epoch 8/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.5447 - val_accuracy: 0.9038\n",
            "Epoch 9/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0227 - accuracy: 0.9937 - val_loss: 0.5404 - val_accuracy: 0.9050\n",
            "Epoch 10/10\n",
            "13679/13679 [==============================] - 109s 8ms/sample - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.5642 - val_accuracy: 0.9056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTkXXuBNNNEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}